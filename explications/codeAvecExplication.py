# Importations n√©cessaires pour l'application web et le traitement de donn√©es
import streamlit as st  # Framework pour cr√©er des applications web interactives en Python
import pandas as pd  # Biblioth√®que pour la manipulation et l'analyse des donn√©es
from sklearn.preprocessing import LabelEncoder  # Outil pour encoder les √©tiquettes textuelles en valeurs num√©riques
from sklearn.model_selection import train_test_split  # Fonction pour diviser les donn√©es en ensembles de test et d'entra√Ænement
from sklearn.svm import SVC  # Importe le mod√®le de Machine √† Vecteurs de Support pour la classification
from sklearn.metrics import precision_score, recall_score  # M√©triques pour √©valuer la pr√©cision et le rappel du mod√®le
# Importations pour afficher diverses m√©triques de performance
from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay
from sklearn.linear_model import LogisticRegression  # Importe le mod√®le de r√©gression logistique
from sklearn.ensemble import RandomForestClassifier  # Importe le mod√®le de for√™t al√©atoire

# D√©finition de la fonction principale de l'application
def main():
    # Affichage du titre de l'application web
    st.title("Binary Classification WebApp")    
    # Description courte sous le titre
    st.markdown("Are your mushroom edible or poisonous? üçÑ")

    # Configuration du titre et de la description dans la barre lat√©rale
    st.sidebar.title("Binary Classification")
    st.sidebar.markdown("Are your mushroom edible or poisonous?")

    # D√©coration de la fonction load_data avec st.cache pour la mise en cache des donn√©es charg√©es
    @st.cache_data(persist=True)
    def load_data():
        # Lecture des donn√©es √† partir d'un fichier CSV
        data = pd.read_csv('mushrooms.csv')
        # Cr√©ation d'un encodeur pour transformer les donn√©es textuelles en num√©riques
        label = LabelEncoder()
        # Encodage de chaque colonne dans le DataFrame
        for col in data.columns:
            data[col] = label.fit_transform(data[col])
        return data  # Retourne le DataFrame encod√©

    # Fonction pour diviser les donn√©es en ensembles d'entra√Ænement et de test
    @st.cache_data(persist=True)
    def split(df):
        # S√©paration de la colonne cible 'type'
        y = df.type
        # Suppression de la colonne cible du DataFrame pour obtenir les caract√©ristiques
        x = df.drop(columns=['type'])
        # Division des donn√©es en ensembles d'entra√Ænement et de test (70% train, 30% test)
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)
        return x_train, x_test, y_train, y_test  # Retourne les ensembles divis√©s

    # Fonction pour afficher les m√©triques s√©lectionn√©es
    def plot_metrics(metrics_list):
        # Affiche la matrice de confusion si s√©lectionn√©e
        if 'Confusion Matrix' in metrics_list:
            st.subheader("Confusion Matrix")
            fig, ax = plt.subplots()  # Cr√©ation d'une figure pour le graphique
            # Affichage de la matrice de confusion √† partir de l'estimateur
            ConfusionMatrixDisplay.from_estimator(model, x_test, y_test, display_labels=class_names, ax=ax)
            st.pyplot(fig)  # Affiche le graphique sur l'application web

        # Affiche la courbe ROC si s√©lectionn√©e
        if 'ROC Curve' in metrics_list:
            st.subheader("ROC Curve")
            fig, ax = plt.subplots()  # Cr√©ation d'une figure pour le graphique
            # Affichage de la courbe ROC √† partir de l'estimateur
            RocCurveDisplay.from_estimator(model, x_test, y_test, ax=ax)
            st.pyplot(fig)  # Affiche le graphique sur l'application web

        # Affiche la courbe Pr√©cision-Rappel si s√©lectionn√©e
        if 'Precision-Recall Curve' in metrics_list:
            st.subheader("Precision-Recall Curve")
            fig, ax = plt.subplots()  # Cr√©ation d'une figure pour le graphique
            # Affichage de la courbe Pr√©cision-Rappel √† partir de l'estimateur
            PrecisionRecallDisplay.from_estimator(model, x_test, y_test, ax=ax)
            st.pyplot(fig)  # Affiche le graphique sur l'application web

    # Chargement des donn√©es et pr√©paration des ensembles d'entra√Ænement et de test
    df = load_data()
    x_train, x_test, y_train, y_test = split(df)
    class_names = ['edible', 'poisonous']  # Noms des classes pour l'affichage

    # Configuration de la s√©lection du classificateur dans la barre lat√©rale
    st.sidebar.subheader("Choose Classifier")
    classifier = st.sidebar.selectbox("Classifier", ("Support Vector Machine (SVM)", "Logistic Regression", "Random Forest"))
    
    # Configuration pour le mod√®le SVM
    if classifier == "Support Vector Machine (SVM)":
        st.sidebar.subheader("Model Hyperparameters")
        # Param√®tres ajustables pour le mod√®le SVM dans la barre lat√©rale
        C = st.sidebar.number_input("C (Regularization parameter)", 0.01, 10.0, step = 0.01, key = 'C')
        kernel = st.sidebar.radio("Kernel", ("rbf", "linear"), key = 'kernel')
        gamma = st.sidebar.radio("Gamma (Kernel Coefficient)", ("scale", "auto"), key = 'auto')
        metrics = st.sidebar.multiselect("What metrics to plot?", ('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))
        
        # Bouton pour lancer la classification
        if st.sidebar.button("Classify", key = 'classify'):
            st.subheader("Support Vector Machine (SVM) Results")
            model = SVC(C = C, kernel = kernel, gamma = gamma)
            model.fit(x_train, y_train)  # Entra√Ænement du mod√®le sur les donn√©es
            accuracy = model.score(x_test, y_test)  # Calcul de la pr√©cision du mod√®le
            y_pred = model.predict(x_test)  # Pr√©diction sur les donn√©es de test
            # Affichage des m√©triques de performance
            st.write("Accuracy: ", accuracy.round(2))
            st.write("Precision: ", precision_score(y_test, y_pred, labels = class_names).round(2))
            st.write("Recall: ", recall_score(y_test, y_pred, labels = class_names).round(2))
            plot_metrics(metrics)  # Appel √† la fonction pour afficher les graphiques s√©lectionn√©s

    # Configuration pour le mod√®le de r√©gression logistique
    if classifier == "Logistic Regression":
        st.sidebar.subheader("Model Hyperparameters")
        # Param√®tres ajustables pour la r√©gression logistique dans la barre lat√©rale
        C = st.sidebar.number_input("C (Regularization parameter)", 0.01, 10.0, step = 0.01, key = 'C_LR')
        max_iter = st.sidebar.slider("Maximum number of iterations", 100, 500, key = 'max_iter')
        metrics = st.sidebar.multiselect("What metrics to plot?", ('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))
        
        # Bouton pour lancer la classification
        if st.sidebar.button("Classify", key = 'classify'):
            st.subheader("Logistic Regression Results")
            model = LogisticRegression(C = C, max_iter = max_iter)
            model.fit(x_train, y_train)  # Entra√Ænement du mod√®le sur les donn√©es
            accuracy = model.score(x_test, y_test)  # Calcul de la pr√©cision du mod√®le
            y_pred = model.predict(x_test)  # Pr√©diction sur les donn√©es de test
            # Affichage des m√©triques de performance
            st.write("Accuracy: ", accuracy.round(2))
            st.write("Precision: ", precision_score(y_test, y_pred, labels = class_names).round(2))
            st.write("Recall: ", recall_score(y_test, y_pred, labels = class_names).round(2))
            plot_metrics(metrics)  # Appel √† la fonction pour afficher les graphiques s√©lectionn√©s

    # Configuration pour le mod√®le de for√™t al√©atoire
    if classifier == "Random Forest":
        st.sidebar.subheader("Model Hyperparameters")
        # Param√®tres ajustables pour la for√™t al√©atoire dans la barre lat√©rale
        n_estimators = st.sidebar.number_input("The number of trees in the forest", 100, 5000, step = 10, key = 'n_estimators')
        max_depth = st.sidebar.number_input("The maximum depth of the tree", 1, 20, step = 1, key = 'max_depth')
        bootstrap = st.sidebar.radio("Bootstrap samples when building trees", ('True', 'False'), key = 'bootstrap')
        metrics = st.sidebar.multiselect("What metrics to plot?", ('Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve'))
        
        # Bouton pour lancer la classification
        if st.sidebar.button("Classify", key = 'classify'):
            st.subheader("Random Forest Results")
            model = RandomForestClassifier(n_estimators = n_estimators, max_depth = max_depth, bootstrap = bootstrap, n_jobs = -1)
            model.fit(x_train, y_train)  # Entra√Ænement du mod√®le sur les donn√©es
            accuracy = model.score(x_test, y_test)  # Calcul de la pr√©cision du mod√®le
            y_pred = model.predict(x_test)  # Pr√©diction sur les donn√©es de test
            # Affichage des m√©triques de performance
            st.write("Accuracy: ", accuracy.round(2))
            st.write("Precision: ", precision_score(y_test, y_pred, labels = class_names).round(2))
            st.write("Recall: ", recall_score(y_test, y_pred, labels = class_names).round(2))
            plot_metrics(metrics)  # Appel √† la fonction pour afficher les graphiques s√©lectionn√©s

    # Option pour afficher les donn√©es brutes
    if st.sidebar.checkbox("Show raw data", False):
        st.subheader("Mushroom Data Set (Classification)")
        st.write(df)  # Affiche le DataFrame sur l'application web

# V√©rifie si le script est ex√©cut√© directement et, dans ce cas, appelle la fonction main
if __name__ == '__main__':
    main()
